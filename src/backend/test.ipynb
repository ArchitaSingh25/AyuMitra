{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f63ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae56a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading from a pdf file\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader('Ashtangahridaya.txt')\n",
    "docs=loader.load()\n",
    "# 3. Split into smaller chunks (important for embeddings & retrieval)\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,chunk_overlap=50)\n",
    "Final_document = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Reading a pdf file\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader=PyPDFLoader(\"/content/Charaka-Samhita-Acharya-Charaka.pdf\")\n",
    "docs=loader.load()\n",
    "\n",
    "# 3. Split into smaller chunks (important for embeddings & retrieval)\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,chunk_overlap=50)\n",
    "Final_document = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be4052",
   "metadata": {},
   "source": [
    "# apply preprocessing for both the files and create a clean document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text_mupdf(text):\n",
    "    # Remove headers/footers\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # Remove empty lines\n",
    "    text = re.sub(r'[^A-Za-z0-9.,;:!?()\\'\\\"\\n]+', ' ', text)  # Remove special characters but keep punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "    return text.strip()\n",
    "\n",
    "for i in range(len(Final_document)):\n",
    "  Final_document[i].page_content=preprocess_text_mupdf(Final_document[i].page_content)\n",
    "\n",
    "# Save the cleaned text to a file\n",
    "with open('Ashtang_cleaned.txt', 'w') as file:\n",
    "    for document in Final_document:\n",
    "        cleaned_text_mupdf = document.page_content\n",
    "        # Write the cleaned text to the file\n",
    "        file.write(cleaned_text_mupdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Load multiple books\n",
    "loader1 = TextLoader(\"D:\\\\AIBootcamp\\\\AyuMitra\\\\bookbank\\\\Ashtang_cleaned.txt\", encoding=\"utf-8\")\n",
    "loader2 = TextLoader(\"D:\\\\AIBootcamp\\\\AyuMitra\\\\bookbank\\\\Charak_cleaned.txt\", encoding=\"utf-8\")\n",
    "\n",
    "docs1 = loader1.load()\n",
    "docs2 = loader2.load()\n",
    "\n",
    "# 2. Combine documents\n",
    "all_docs = docs1 + docs2\n",
    "\n",
    "# 3. Split into smaller chunks (important for embeddings & retrieval)\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,chunk_overlap=50)\n",
    "Final_document = text_splitter.split_documents(all_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33616a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4524"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Final_document)  # Check the number of chunks created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccee606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_4196\\4286477000.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\vedbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502df482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "not needed\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(Final_document, embedding=embeddings, collection_name=\"bookstore\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70ef72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chroma DB saved at D:\\AIBootcamp\\AyuMitra\\db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_17788\\2623306549.py:10: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "# Create a persistent Chroma DB\n",
    "persist_directory = r\"D:\\AIBootcamp\\AyuMitra\\db\"  # use raw string for Windows paths\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents=Final_document,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"bookstore\",\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "db.persist()\n",
    "print(\" Chroma DB saved at\", persist_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a39828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableMap\n",
    "#To get a callable obebject to map result\n",
    "retriever=db.as_retriever()\n",
    "# This gets relevant context documents and prepares inputs for the prompt\n",
    "retrieval_chain = (\n",
    "    RunnableMap({\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"context\": lambda x: \"\\n\\n\".join(\n",
    "            doc.page_content for doc in retriever.get_relevant_documents(x[\"question\"])\n",
    "        )\n",
    "    })\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5673bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d692deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/AIBootcamp/AyuMitra/prompt/system_prompt.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch system prompt path from env\n",
    "system_prompt_path = os.getenv(\"SYSTEM_PROMPT_PATH\")\n",
    "print(system_prompt_path)\n",
    "\n",
    "if not system_prompt_path:\n",
    "    raise ValueError(\"SYSTEM_PROMPT_PATH not set in .env file\")\n",
    "\n",
    "# Load system prompt from text file\n",
    "with open(system_prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    system_prompt = f.read()\n",
    "\n",
    "# Build Ayurvedic Medical Bot Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are Ayurbot, an expert Ayurvedic assistant.\n",
    "You act as a doctor and use only the provided context (from Charaka Samhita) \n",
    "to generate remedies, medications, and lifestyle advice for the patient.\n",
    "\n",
    "Response Guidelines:\n",
    "- Always answer in the following format:\n",
    "  **User (Patient):** <Repeat the question or symptoms>\n",
    "  **Chatbot (Ayurvedic Bot):** <Provide remedies/medications>\n",
    "\n",
    "- Use Ayurvedic principles (Doshas, Agni, Ojas, Dinacharya, Ritucharya) where relevant.\n",
    "- Present remedies step-by-step (ingredients, preparation, dosage, timing).\n",
    "- If possible, give more than one option (home remedy, classical formulation, lifestyle advice).\n",
    "- Mention precautions (pregnancy, chronic illness, interactions with other medicines).\n",
    "- If the condition is severe or life-threatening, advise seeking immediate medical care.\n",
    "- Do not generate answers outside the given context.\n",
    "- End EVERY answer with this disclaimer:\n",
    "\"⚠️ Please confirm this remedy or medication with a certified Ayurvedic practitioner or healthcare expert before following it.\"\n",
    "\"\"\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d5d3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Ayurvedic Medical Bot Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are Ayurbot, an expert Ayurvedic assistant.\n",
    "You act as a doctor and use only the provided context\n",
    "to generate remedies, medications, and lifestyle advice for the patient.\n",
    "\n",
    "Response Guidelines:\n",
    "- Always answer in the following format:\n",
    "  **User (Patient):** <Repeat the question or symptoms>\n",
    "  **Chatbot (Ayurvedic Bot):** <Provide remedies/medications>\n",
    "\n",
    "- Use Ayurvedic principles (Doshas, Agni, Ojas, Dinacharya, Ritucharya) where relevant.\n",
    "- Present remedies step-by-step (ingredients, preparation, dosage, timing).\n",
    "- If possible, give more than one option (home remedy, classical formulation, lifestyle advice).\n",
    "- Mention precautions (pregnancy, chronic illness, interactions with other medicines).\n",
    "- If the condition is severe or life-threatening, advise seeking immediate medical care.\n",
    "- Do not generate answers outside the given context.\n",
    "- End EVERY answer with this disclaimer:\n",
    "\"⚠️ Please confirm this remedy or medication with a certified Ayurvedic practitioner or healthcare expert before following it.\"\n",
    "\"\"\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3d7ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0.5,\n",
    "    max_output_tokens=4096\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e048d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# For parsing output\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "# Final chain\n",
    "chain = retrieval_chain | prompt | llm | output_parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bace5477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**User (Patient):** I feel severe pain in urinary bladder,intense pain in penis, frequent urination in less quantity.\n",
      "**Chatbot (Ayurvedic Bot):**\n",
      "\n",
      "Based on your symptoms, here are some potential remedies:\n",
      "\n",
      "*   **Home Remedy:**\n",
      "\n",
      "    *   **Warm Sitz Bath (Avagaha):** Take a warm tub bath to relieve pain in the bladder and groin region.\n",
      "*   **Classical Formulations & Ayurvedic Therapies:**\n",
      "\n",
      "    *   **Vasti Karma (Medicated Enema):** This can help with urinary and pain-related issues. Different types of Vasti can be used based on your specific condition.\n",
      "    *   **Abhyanga (Body Massage with Oils):** Full body massage can help alleviate body ache.\n",
      "*   **Lifestyle Advice:**\n",
      "\n",
      "    *   Avoid suppressing the urge to urinate.\n",
      "    *   Stay hydrated, but avoid excessive water intake during the urge to urinate.\n",
      "    *   Avoid coitus when you have the urge to urinate.\n",
      "\n",
      "⚠️ Please confirm this remedy or medication with a certified Ayurvedic practitioner or healthcare expert before following it.\n"
     ]
    }
   ],
   "source": [
    "query = \" I feel severe pain in urinary bladder,intense pain in penis ,frequent urination in less quantity\"\n",
    "\n",
    "\n",
    "rag_answer=chain.invoke({\"question\":query})\n",
    "print(rag_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "329d9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Generate an embedding for a given text.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "    - The sentence embedding.\n",
    "    \"\"\"\n",
    "    # Generate the sentence embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    return embeddings.embed_query(text)\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two embeddings.\n",
    "\n",
    "    Args:\n",
    "    - embedding1 (torch.Tensor): The first embedding.\n",
    "    - embedding2 (torch.Tensor): The second embedding.\n",
    "\n",
    "    Returns:\n",
    "    - The cosine similarity score.\n",
    "    \"\"\"\n",
    "    # Calculate the cosine similarity\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(true_answer, rag_answer, non_rag_answer):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity scores between the true answer and both RAG-based and non-RAG-based answers.\n",
    "\n",
    "    Args:\n",
    "    - true_answer (str): The true answer text.\n",
    "    - rag_answer (str): The RAG-based model's answer text.\n",
    "    - non_rag_answer (str): The non-RAG-based model's answer text.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with cosine similarity scores.\n",
    "    \"\"\"\n",
    "    # Convert the answers to embeddings\n",
    "    true_answer_embedding = get_embedding(true_answer)\n",
    "    rag_answer_embedding = get_embedding(rag_answer)\n",
    "    non_rag_answer_embedding = get_embedding(non_rag_answer)\n",
    "\n",
    "    # Calculate cosine similarity scores\n",
    "    rag_similarity = calculate_cosine_similarity(true_answer_embedding, rag_answer_embedding)\n",
    "    non_rag_similarity = calculate_cosine_similarity(true_answer_embedding, non_rag_answer_embedding)\n",
    "\n",
    "\n",
    "    # Return the scores\n",
    "    return {\n",
    "        \"RAG Similarity Score\": rag_similarity,\n",
    "        \"Non-RAG Similarity Score\": non_rag_similarity\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "200e31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_answer = \"\"\"**Ayurvedic Remedies**\n",
    "\n",
    "*   **Classical Formulation:**\n",
    "    *   **Punarnavadi Kashayam:** This classical Ayurvedic decoction is known for its diuretic and anti-inflammatory properties, which can help alleviate bladder pain and promote healthy urine flow.\n",
    "        *   **Ingredients:** Punarnava (Boerhavia diffusa) and other herbs.\n",
    "        *   **Preparation:** Usually available as a ready-made decoction.\n",
    "        *   **Dosage:** 15-20 ml, mixed with an equal amount of warm water, twice daily after food.\n",
    "        *   **Timing:** Morning and evening after meals.\n",
    "\n",
    "**Lifestyle Adjustments**\n",
    "\n",
    "*   **Hydration:** Drink plenty of fluids (warm water, herbal teas) to help flush out the urinary system and reduce burning sensations.\n",
    "*   **Avoid Suppressing Urges:** Always heed the natural urge to urinate. Suppressing it can lead to imbalances and pain.\n",
    "*   **Warm Compress:** Apply a warm compress to the lower abdomen to help soothe the bladder and alleviate pain.\n",
    "\n",
    "**Precautions:**\n",
    "\n",
    "*   If you have a known history of kidney stones or any chronic urinary condition, consult with a healthcare provider before trying these remedies.\n",
    "*   If you experience fever, severe pain, or blood in the urine, seek immediate medical attention.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bf93e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RAG Similarity Score': np.float64(0.7142274190583674), 'Non-RAG Similarity Score': np.float64(1.0)}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the similarity scores\n",
    "similarity_scores = calculate_similarity_scores(true_answer, rag_answer, true_answer)\n",
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c2def64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_logic import load_db, build_chain,build_conversational_chain,get_session_history\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "db=load_db(embeddings)  # or \"Cases\" based on your choice\n",
    "chain, retriever, config=build_conversational_chain(db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_17596\\2766215191.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\vedbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db=load_db(embeddings)  # or \"Cases\" based on your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ae0f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain,retriever=build_chain(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a806f6f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing keys ['session_id'] in config['configurable'] Expected keys are ['session_id'].When using via .invoke() or .stream(), pass in a config; e.g., chain.invoke({'question': 'foo'}, {'configurable': {'session_id': '[your-value-here]'}})",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33m I feel severe pain in urinary bladder,intense pain in penis ,frequent urination in less quantity\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m rag_answer=\u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(rag_answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\anaconda3\\envs\\vedbot\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5497\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5488\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5490\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5493\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5494\u001b[39m ) -> Output:\n\u001b[32m   5495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.invoke(\n\u001b[32m   5496\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m5497\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   5498\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5499\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\anaconda3\\envs\\vedbot\\Lib\\site-packages\\langchain_core\\runnables\\history.py:596\u001b[39m, in \u001b[36mRunnableWithMessageHistory._merge_configs\u001b[39m\u001b[34m(self, *configs)\u001b[39m\n\u001b[32m    589\u001b[39m     example_config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: example_configurable}\n\u001b[32m    590\u001b[39m     msg = (\n\u001b[32m    591\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(missing_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in config[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    592\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected keys are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(expected_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    593\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWhen using via .invoke() or .stream(), pass in a config; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    594\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33me.g., chain.invoke(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    595\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(expected_keys) == \u001b[32m1\u001b[39m:\n\u001b[32m    599\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parameter_names:\n\u001b[32m    600\u001b[39m         \u001b[38;5;66;03m# If arity = 1, then invoke function by positional arguments\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Missing keys ['session_id'] in config['configurable'] Expected keys are ['session_id'].When using via .invoke() or .stream(), pass in a config; e.g., chain.invoke({'question': 'foo'}, {'configurable': {'session_id': '[your-value-here]'}})"
     ]
    }
   ],
   "source": [
    "query = \" I feel severe pain in urinary bladder,intense pain in penis ,frequent urination in less quantity\"\n",
    "\n",
    "\n",
    "rag_answer=chain.invoke({\"question\":query})\n",
    "print(rag_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d70e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_23124\\686652566.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\vedbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the symptoms and context provided, here are some Ayurvedic remedies that might help:\n",
      "\n",
      "**Understanding the Ayurvedic Approach:**\n",
      "\n",
      "*   The symptoms suggest an imbalance of Vata dosha, leading to pain, obstruction, and urinary issues.\n",
      "*   The treatment aims to balance Vata, promote proper elimination, and soothe the affected areas.\n",
      "\n",
      "**Ayurvedic Remedies:**\n",
      "\n",
      "1.  **Home Remedy for Urinary Discomfort:**\n",
      "\n",
      "    *   **Ingredients:**\n",
      "        *   Warm water\n",
      "        *   1/2 teaspoon of Yavakshar (Potassium Carbonate)\n",
      "    *   **Preparation:** Mix Yavakshar in warm water.\n",
      "    *   **Dosage:** Drink this once or twice a day.\n",
      "    *   **Timing:** Preferably on an empty stomach or between meals.\n",
      "    *   **Benefits:** Yavakshar helps in relieving urinary obstruction and pain.\n",
      "    *   **Precautions:** Use under supervision, as high doses may cause gastric irritation.\n",
      "\n",
      "2.  **Classical Ayurvedic Formulation: Chandraprabha Vati**\n",
      "\n",
      "    *   **Ingredients:** A classical Ayurvedic medicine with a combination of herbs.\n",
      "    *   **Dosage:** 1-2 tablets twice daily.\n",
      "    *   **Timing:** After food with warm water.\n",
      "    *   **Benefits:** Useful in urinary disorders, bladder issues, and pain relief.\n",
      "    *   **Precautions:** Consult a physician before use, especially if you have diabetes or hypertension.\n",
      "\n",
      "3.  **Lifestyle Adjustments:**\n",
      "\n",
      "    *   **Diet:**\n",
      "        *   Include carminative foods like ginger, cumin, and asafoetida in your diet.\n",
      "        *   Avoid suppressing natural urges like urination and passing flatus.\n",
      "    *   **Dinacharya (Daily Routine):**\n",
      "        *   Perform Abhyanga (oil massage) with sesame oil to pacify Vata.\n",
      "        *   Take a warm sitz bath (Avagaha) to soothe the pelvic region.\n",
      "\n",
      "4.  **Herbal Remedy for Pain Relief:**\n",
      "\n",
      "    *   **Ingredients:**\n",
      "        *   Dashamoola powder\n",
      "    *   **Preparation:** Boil 1 teaspoon of Dashamoola powder in 2 cups of water until it reduces to half.\n",
      "    *   **Dosage:** Drink this decoction twice a day.\n",
      "    *   **Timing:** Preferably before meals.\n",
      "    *   **Benefits:** Dashamoola helps in relieving body ache and pain associated with urinary issues.\n",
      "    *   **Precautions:** Avoid if you have a known allergy to any of the herbs in Dashamoola.\n",
      "\n",
      "5.  **Vasti Karma (Enema Therapy):**\n",
      "\n",
      "    *   **Type:** Non-unctuous enema with carminative herbs.\n",
      "    *   **Benefits:** Helps in relieving flatulence and abdominal discomfort.\n",
      "    *   **Note:** This should be administered by a trained Ayurvedic practitioner.\n",
      "\n",
      "⚠️ Please confirm this remedy or medication with a certified Ayurvedic practitioner or healthcare expert before following it.\n"
     ]
    }
   ],
   "source": [
    "from rag_logic import load_db, build_conversational_chain\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load embeddings + DB\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = load_db(embeddings)\n",
    "\n",
    "# Get conversational chain\n",
    "chain, retriever, config = build_conversational_chain(db)\n",
    "\n",
    "# Query\n",
    "query = \"I feel severe pain in urinary bladder, intense pain in penis, frequent urination in less quantity\"\n",
    "\n",
    "# ✅ Pass dict, not list\n",
    "rag_answer = chain.invoke({\"question\": query}, config=config)\n",
    "print(rag_answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61cda58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   **Classical Ayurvedic Formulation:**\n",
      "    *   **Medication:** Chandraprabha Vati\n",
      "    *   **Dosage:** 1-2 tablets twice daily\n",
      "    *   **Timing:** After food with warm water\n",
      "    *   **Benefits:** It helps in relieving urinary problems.\n",
      "\n",
      "Please confirm this remedy or medication with a certified Ayurvedic practitioner or healthcare expert before following it.\n"
     ]
    }
   ],
   "source": [
    "query = \"give me only classical formulations from above answer with no changes\"\n",
    "\n",
    "# ✅ Pass dict, not list\n",
    "rag_answer = chain.invoke({\"question\": query}, config=config)\n",
    "print(rag_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5545d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_logic import save_feedback\n",
    "query = \"give me only classical formulations from above answer with no changes\"\n",
    "\n",
    "rag_answer=\"testing\"\n",
    "save_feedback(\n",
    "    query=query,\n",
    "    bot_output=rag_answer,\n",
    "    doctor_feedback=\"correct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b465fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"I have legs stiffness+thighs stiffness+wrist stiffness\"\n",
    "\n",
    "# ✅ Pass dict, not list\n",
    "rag_answer = chain.invoke({\"question\": query}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0391d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rag_logic import load_db, build_conversational_chain\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# ================================\n",
    "# Load Embeddings + DB + Chain\n",
    "# ================================\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = load_db(embeddings)\n",
    "conv_chain, retriever, config = build_conversational_chain(db, session_id=\"excel_run\")\n",
    "\n",
    "# ================================\n",
    "# File paths\n",
    "# ================================\n",
    "input_file = \"Filtered.xlsx\"\n",
    "output_file = \"Disease_symptoms_with_answers.xlsx\"\n",
    "\n",
    "# Load all sheets\n",
    "sheets_dict = pd.read_excel(input_file)\n",
    "\n",
    "output_sheets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "875f1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for query in sheets_dict['symptoms']:  # assuming column is \"symptom\"\n",
    "    rag_answer = conv_chain.invoke({\"question\": query}, config=config)\n",
    "    results.append({\"query\": query, \"RAG_Answer\": rag_answer})\n",
    "\n",
    "# Convert to DataFrame for saving\n",
    "output_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "006f5195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>RAG_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fever+cough+hiccups+asthama+change in taste of...</td>\n",
       "      <td>Based on the symptoms provided, here is an Ayu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tachycardia+feeling of dryness in heart++stiff...</td>\n",
       "      <td>Based on the symptoms provided, here is an Ayu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heart burn+syncope+to be afraid+fever+heat up+...</td>\n",
       "      <td>Based on the symptoms provided, here is an Ayu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heaviness in heart+stiffness in heart+dribblin...</td>\n",
       "      <td>Based on the symptoms provided, here is an Ayu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intense heart ache+pricking pain in heart+itch...</td>\n",
       "      <td>Based on the symptoms provided, here is an Ayu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  fever+cough+hiccups+asthama+change in taste of...   \n",
       "1  tachycardia+feeling of dryness in heart++stiff...   \n",
       "2  heart burn+syncope+to be afraid+fever+heat up+...   \n",
       "3  heaviness in heart+stiffness in heart+dribblin...   \n",
       "4  intense heart ache+pricking pain in heart+itch...   \n",
       "\n",
       "                                          RAG_Answer  \n",
       "0  Based on the symptoms provided, here is an Ayu...  \n",
       "1  Based on the symptoms provided, here is an Ayu...  \n",
       "2  Based on the symptoms provided, here is an Ayu...  \n",
       "3  Based on the symptoms provided, here is an Ayu...  \n",
       "4  Based on the symptoms provided, here is an Ayu...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dedefa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "816f9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# Use the same model name as in conv_chain config\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "035b24cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved RAG vs Gemini results with similarity to RAG_vs_Gemini_with_Similarity.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from rag_logic import load_db, build_conversational_chain\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# ================================\n",
    "# Load Gemini LLM (baseline)\n",
    "# ================================\n",
    "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "# ================================\n",
    "# Embeddings for similarity\n",
    "# ================================\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ================================\n",
    "# Collect results\n",
    "# ================================\n",
    "baseline_results = []\n",
    "\n",
    "for query in sheets_dict['symptoms']:\n",
    "    # Direct Gemini answer\n",
    "    gemini_answer = gemini_llm.invoke(query)\n",
    "    gemini_text = gemini_answer.content if hasattr(gemini_answer, \"content\") else str(gemini_answer)\n",
    "\n",
    "    # RAG answer\n",
    "    rag_answer = conv_chain.invoke({\"question\": query}, config=config)\n",
    "    rag_text = rag_answer if isinstance(rag_answer, str) else str(rag_answer)\n",
    "\n",
    "    # Compute embeddings\n",
    "    gemini_vec = embeddings_model.embed_query(gemini_text)\n",
    "    rag_vec = embeddings_model.embed_query(rag_text)\n",
    "\n",
    "    # Cosine similarity\n",
    "    similarity = cosine_similarity([gemini_vec], [rag_vec])[0][0]\n",
    "\n",
    "    # Save results\n",
    "    baseline_results.append({\n",
    "        \"query\": query,\n",
    "        \"Gemini_Answer\": gemini_text,\n",
    "        \"RAG_Answer\": rag_text,\n",
    "        \"Similarity_Score\": round(similarity, 4)\n",
    "    })\n",
    "\n",
    "    time.sleep(5)  # avoid hitting Gemini quota\n",
    "\n",
    "# ================================\n",
    "# Save to Excel\n",
    "# ================================\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "baseline_df.to_excel(\"RAG_vs_Gemini_with_Similarity.xlsx\", index=False)\n",
    "\n",
    "print(\"✅ Saved RAG vs Gemini results with similarity to RAG_vs_Gemini_with_Similarity.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vedbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
